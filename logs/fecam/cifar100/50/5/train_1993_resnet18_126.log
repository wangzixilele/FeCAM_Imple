2024-06-18 20:11:56,884 [trainer.py] => config: exps/FeCAM_cifar100.json
2024-06-18 20:11:56,884 [trainer.py] => prefix: train
2024-06-18 20:11:56,884 [trainer.py] => dataset: cifar100
2024-06-18 20:11:56,884 [trainer.py] => memory_size: 0
2024-06-18 20:11:56,884 [trainer.py] => shuffle: True
2024-06-18 20:11:56,884 [trainer.py] => init_cls: 50
2024-06-18 20:11:56,884 [trainer.py] => increment: 5
2024-06-18 20:11:56,884 [trainer.py] => model_name: fecam
2024-06-18 20:11:56,884 [trainer.py] => convnet_type: resnet18
2024-06-18 20:11:56,884 [trainer.py] => device: [device(type='cuda', index=0), device(type='cuda', index=3)]
2024-06-18 20:11:56,884 [trainer.py] => seed: 1993
2024-06-18 20:11:56,884 [trainer.py] => init_epochs: 200
2024-06-18 20:11:56,884 [trainer.py] => init_lr: 0.1
2024-06-18 20:11:56,884 [trainer.py] => init_weight_decay: 0.0005
2024-06-18 20:11:56,884 [trainer.py] => batch_size: 128
2024-06-18 20:11:56,884 [trainer.py] => num_workers: 8
2024-06-18 20:11:56,884 [trainer.py] => T: 2
2024-06-18 20:11:56,884 [trainer.py] => beta: 0.5
2024-06-18 20:11:56,884 [trainer.py] => alpha1: 1
2024-06-18 20:11:56,884 [trainer.py] => alpha2: 1
2024-06-18 20:11:56,884 [trainer.py] => ncm: False
2024-06-18 20:11:56,884 [trainer.py] => tukey: True
2024-06-18 20:11:56,884 [trainer.py] => diagonal: False
2024-06-18 20:11:56,884 [trainer.py] => per_class: True
2024-06-18 20:11:56,884 [trainer.py] => full_cov: True
2024-06-18 20:11:56,884 [trainer.py] => shrink: True
2024-06-18 20:11:56,884 [trainer.py] => norm_cov: True
2024-06-18 20:11:58,491 [data_manager.py] => [68, 56, 78, 8, 23, 84, 90, 65, 74, 76, 40, 89, 3, 92, 55, 9, 26, 80, 43, 38, 58, 70, 77, 1, 85, 19, 17, 50, 28, 53, 13, 81, 45, 82, 6, 59, 83, 16, 15, 44, 91, 41, 72, 60, 79, 52, 20, 10, 31, 54, 37, 95, 14, 71, 96, 98, 97, 2, 64, 66, 42, 22, 35, 86, 24, 34, 87, 21, 99, 0, 88, 27, 18, 94, 11, 12, 47, 25, 30, 46, 62, 69, 36, 61, 7, 63, 75, 5, 32, 4, 51, 48, 73, 93, 39, 67, 29, 49, 57, 33]
2024-06-18 20:11:58,715 [fecam.py] => Learning on 0-50
2024-06-18 20:12:35,674 [fecam.py] => Task 0, Epoch 1/200 => Loss 3.711, Train_accy 6.45, Test_accy 12.02
2024-06-18 20:12:39,012 [fecam.py] => Task 0, Epoch 2/200 => Loss 3.339, Train_accy 13.77
2024-06-18 20:12:42,372 [fecam.py] => Task 0, Epoch 3/200 => Loss 3.039, Train_accy 19.84
2024-06-18 20:12:45,745 [fecam.py] => Task 0, Epoch 4/200 => Loss 2.743, Train_accy 25.66
2024-06-18 20:12:49,170 [fecam.py] => Task 0, Epoch 5/200 => Loss 2.471, Train_accy 32.73
2024-06-18 20:12:53,403 [fecam.py] => Task 0, Epoch 6/200 => Loss 2.252, Train_accy 37.83, Test_accy 40.72
2024-06-18 20:12:56,806 [fecam.py] => Task 0, Epoch 7/200 => Loss 2.088, Train_accy 42.00
2024-06-18 20:13:00,221 [fecam.py] => Task 0, Epoch 8/200 => Loss 1.944, Train_accy 45.35
2024-06-18 20:13:03,631 [fecam.py] => Task 0, Epoch 9/200 => Loss 1.837, Train_accy 48.10
2024-06-18 20:13:07,021 [fecam.py] => Task 0, Epoch 10/200 => Loss 1.744, Train_accy 50.63
2024-06-18 20:13:11,423 [fecam.py] => Task 0, Epoch 11/200 => Loss 1.679, Train_accy 52.52, Test_accy 56.78
2024-06-18 20:13:14,986 [fecam.py] => Task 0, Epoch 12/200 => Loss 1.619, Train_accy 53.91
2024-06-18 20:13:18,526 [fecam.py] => Task 0, Epoch 13/200 => Loss 1.577, Train_accy 55.00
2024-06-18 20:13:22,070 [fecam.py] => Task 0, Epoch 14/200 => Loss 1.528, Train_accy 56.40
2024-06-18 20:13:25,605 [fecam.py] => Task 0, Epoch 15/200 => Loss 1.493, Train_accy 57.32
2024-06-18 20:13:30,119 [fecam.py] => Task 0, Epoch 16/200 => Loss 1.468, Train_accy 58.28, Test_accy 59.86
2024-06-18 20:13:33,639 [fecam.py] => Task 0, Epoch 17/200 => Loss 1.446, Train_accy 58.60
2024-06-18 20:13:37,175 [fecam.py] => Task 0, Epoch 18/200 => Loss 1.417, Train_accy 59.63
2024-06-18 20:13:40,709 [fecam.py] => Task 0, Epoch 19/200 => Loss 1.393, Train_accy 60.12
2024-06-18 20:13:44,253 [fecam.py] => Task 0, Epoch 20/200 => Loss 1.368, Train_accy 60.58
2024-06-18 20:13:48,801 [fecam.py] => Task 0, Epoch 21/200 => Loss 1.351, Train_accy 61.40, Test_accy 64.50
2024-06-18 20:13:52,350 [fecam.py] => Task 0, Epoch 22/200 => Loss 1.340, Train_accy 61.68
2024-06-18 20:13:55,888 [fecam.py] => Task 0, Epoch 23/200 => Loss 1.307, Train_accy 62.58
2024-06-18 20:13:59,437 [fecam.py] => Task 0, Epoch 24/200 => Loss 1.284, Train_accy 63.04
2024-06-18 20:14:02,964 [fecam.py] => Task 0, Epoch 25/200 => Loss 1.283, Train_accy 63.44
2024-06-18 20:14:07,475 [fecam.py] => Task 0, Epoch 26/200 => Loss 1.274, Train_accy 63.62, Test_accy 61.22
2024-06-18 20:14:11,015 [fecam.py] => Task 0, Epoch 27/200 => Loss 1.258, Train_accy 63.83
2024-06-18 20:14:14,561 [fecam.py] => Task 0, Epoch 28/200 => Loss 1.230, Train_accy 64.68
2024-06-18 20:14:18,107 [fecam.py] => Task 0, Epoch 29/200 => Loss 1.237, Train_accy 64.84
2024-06-18 20:14:21,649 [fecam.py] => Task 0, Epoch 30/200 => Loss 1.222, Train_accy 64.92
2024-06-18 20:14:26,189 [fecam.py] => Task 0, Epoch 31/200 => Loss 1.210, Train_accy 65.22, Test_accy 65.74
2024-06-18 20:14:29,769 [fecam.py] => Task 0, Epoch 32/200 => Loss 1.204, Train_accy 65.22
2024-06-18 20:14:33,307 [fecam.py] => Task 0, Epoch 33/200 => Loss 1.184, Train_accy 65.94
2024-06-18 20:14:36,841 [fecam.py] => Task 0, Epoch 34/200 => Loss 1.186, Train_accy 65.70
2024-06-18 20:14:40,394 [fecam.py] => Task 0, Epoch 35/200 => Loss 1.177, Train_accy 66.09
2024-06-18 20:14:44,900 [fecam.py] => Task 0, Epoch 36/200 => Loss 1.168, Train_accy 66.62, Test_accy 64.00
2024-06-18 20:14:48,420 [fecam.py] => Task 0, Epoch 37/200 => Loss 1.158, Train_accy 66.47
2024-06-18 20:14:51,975 [fecam.py] => Task 0, Epoch 38/200 => Loss 1.151, Train_accy 66.71
2024-06-18 20:14:55,552 [fecam.py] => Task 0, Epoch 39/200 => Loss 1.153, Train_accy 66.78
2024-06-18 20:14:59,117 [fecam.py] => Task 0, Epoch 40/200 => Loss 1.124, Train_accy 67.76
2024-06-18 20:15:03,681 [fecam.py] => Task 0, Epoch 41/200 => Loss 1.131, Train_accy 67.45, Test_accy 66.34
2024-06-18 20:15:07,259 [fecam.py] => Task 0, Epoch 42/200 => Loss 1.108, Train_accy 68.12
2024-06-18 20:15:10,816 [fecam.py] => Task 0, Epoch 43/200 => Loss 1.114, Train_accy 67.89
2024-06-18 20:15:14,367 [fecam.py] => Task 0, Epoch 44/200 => Loss 1.108, Train_accy 67.82
2024-06-18 20:15:17,924 [fecam.py] => Task 0, Epoch 45/200 => Loss 1.080, Train_accy 68.83
2024-06-18 20:15:22,432 [fecam.py] => Task 0, Epoch 46/200 => Loss 1.100, Train_accy 68.36, Test_accy 67.32
2024-06-18 20:15:25,987 [fecam.py] => Task 0, Epoch 47/200 => Loss 1.077, Train_accy 68.91
2024-06-18 20:15:29,534 [fecam.py] => Task 0, Epoch 48/200 => Loss 1.067, Train_accy 69.10
2024-06-18 20:15:33,092 [fecam.py] => Task 0, Epoch 49/200 => Loss 1.071, Train_accy 68.96
2024-06-18 20:15:36,642 [fecam.py] => Task 0, Epoch 50/200 => Loss 1.046, Train_accy 69.55
2024-06-18 20:15:41,163 [fecam.py] => Task 0, Epoch 51/200 => Loss 1.063, Train_accy 69.14, Test_accy 67.14
2024-06-18 20:15:44,725 [fecam.py] => Task 0, Epoch 52/200 => Loss 1.041, Train_accy 69.70
2024-06-18 20:15:48,266 [fecam.py] => Task 0, Epoch 53/200 => Loss 1.047, Train_accy 70.07
2024-06-18 20:15:51,820 [fecam.py] => Task 0, Epoch 54/200 => Loss 1.047, Train_accy 70.13
2024-06-18 20:15:55,381 [fecam.py] => Task 0, Epoch 55/200 => Loss 1.023, Train_accy 70.39
2024-06-18 20:15:59,959 [fecam.py] => Task 0, Epoch 56/200 => Loss 1.030, Train_accy 70.24, Test_accy 66.76
2024-06-18 20:16:03,540 [fecam.py] => Task 0, Epoch 57/200 => Loss 1.028, Train_accy 70.43
2024-06-18 20:16:07,097 [fecam.py] => Task 0, Epoch 58/200 => Loss 1.017, Train_accy 70.65
2024-06-18 20:16:10,655 [fecam.py] => Task 0, Epoch 59/200 => Loss 1.008, Train_accy 70.75
2024-06-18 20:16:14,250 [fecam.py] => Task 0, Epoch 60/200 => Loss 1.004, Train_accy 70.95
2024-06-18 20:16:18,773 [fecam.py] => Task 0, Epoch 61/200 => Loss 1.007, Train_accy 71.06, Test_accy 67.98
2024-06-18 20:16:22,319 [fecam.py] => Task 0, Epoch 62/200 => Loss 0.997, Train_accy 71.36
2024-06-18 20:16:25,874 [fecam.py] => Task 0, Epoch 63/200 => Loss 0.995, Train_accy 71.11
2024-06-18 20:16:29,423 [fecam.py] => Task 0, Epoch 64/200 => Loss 0.986, Train_accy 71.68
2024-06-18 20:16:32,962 [fecam.py] => Task 0, Epoch 65/200 => Loss 0.979, Train_accy 71.82
2024-06-18 20:16:37,477 [fecam.py] => Task 0, Epoch 66/200 => Loss 0.971, Train_accy 72.00, Test_accy 68.60
2024-06-18 20:16:41,009 [fecam.py] => Task 0, Epoch 67/200 => Loss 0.955, Train_accy 72.16
2024-06-18 20:16:44,561 [fecam.py] => Task 0, Epoch 68/200 => Loss 0.967, Train_accy 71.93
2024-06-18 20:16:48,109 [fecam.py] => Task 0, Epoch 69/200 => Loss 0.938, Train_accy 72.57
2024-06-18 20:16:51,668 [fecam.py] => Task 0, Epoch 70/200 => Loss 0.951, Train_accy 72.55
2024-06-18 20:16:56,196 [fecam.py] => Task 0, Epoch 71/200 => Loss 0.960, Train_accy 72.32, Test_accy 68.44
2024-06-18 20:16:59,742 [fecam.py] => Task 0, Epoch 72/200 => Loss 0.926, Train_accy 72.89
2024-06-18 20:17:03,287 [fecam.py] => Task 0, Epoch 73/200 => Loss 0.933, Train_accy 72.98
2024-06-18 20:17:06,837 [fecam.py] => Task 0, Epoch 74/200 => Loss 0.926, Train_accy 73.20
2024-06-18 20:17:10,383 [fecam.py] => Task 0, Epoch 75/200 => Loss 0.901, Train_accy 74.15
2024-06-18 20:17:14,923 [fecam.py] => Task 0, Epoch 76/200 => Loss 0.906, Train_accy 73.82, Test_accy 67.70
2024-06-18 20:17:18,468 [fecam.py] => Task 0, Epoch 77/200 => Loss 0.906, Train_accy 73.74
2024-06-18 20:17:22,034 [fecam.py] => Task 0, Epoch 78/200 => Loss 0.899, Train_accy 73.98
2024-06-18 20:17:25,599 [fecam.py] => Task 0, Epoch 79/200 => Loss 0.884, Train_accy 74.42
2024-06-18 20:17:29,153 [fecam.py] => Task 0, Epoch 80/200 => Loss 0.889, Train_accy 74.11
2024-06-18 20:17:33,692 [fecam.py] => Task 0, Epoch 81/200 => Loss 0.877, Train_accy 74.34, Test_accy 69.62
2024-06-18 20:17:37,247 [fecam.py] => Task 0, Epoch 82/200 => Loss 0.852, Train_accy 75.43
2024-06-18 20:17:40,780 [fecam.py] => Task 0, Epoch 83/200 => Loss 0.852, Train_accy 75.28
2024-06-18 20:17:44,372 [fecam.py] => Task 0, Epoch 84/200 => Loss 0.866, Train_accy 74.75
2024-06-18 20:17:47,917 [fecam.py] => Task 0, Epoch 85/200 => Loss 0.847, Train_accy 75.48
2024-06-18 20:17:52,445 [fecam.py] => Task 0, Epoch 86/200 => Loss 0.844, Train_accy 75.40, Test_accy 65.84
2024-06-18 20:17:55,991 [fecam.py] => Task 0, Epoch 87/200 => Loss 0.827, Train_accy 76.12
2024-06-18 20:17:59,555 [fecam.py] => Task 0, Epoch 88/200 => Loss 0.828, Train_accy 76.10
2024-06-18 20:18:03,080 [fecam.py] => Task 0, Epoch 89/200 => Loss 0.816, Train_accy 76.30
2024-06-18 20:18:06,625 [fecam.py] => Task 0, Epoch 90/200 => Loss 0.814, Train_accy 76.51
2024-06-18 20:18:11,156 [fecam.py] => Task 0, Epoch 91/200 => Loss 0.810, Train_accy 76.20, Test_accy 70.22
2024-06-18 20:18:14,697 [fecam.py] => Task 0, Epoch 92/200 => Loss 0.820, Train_accy 76.36
2024-06-18 20:18:18,266 [fecam.py] => Task 0, Epoch 93/200 => Loss 0.809, Train_accy 76.95
2024-06-18 20:18:21,854 [fecam.py] => Task 0, Epoch 94/200 => Loss 0.785, Train_accy 77.21
2024-06-18 20:18:25,420 [fecam.py] => Task 0, Epoch 95/200 => Loss 0.794, Train_accy 76.95
2024-06-18 20:18:29,929 [fecam.py] => Task 0, Epoch 96/200 => Loss 0.772, Train_accy 77.76, Test_accy 72.98
2024-06-18 20:18:33,494 [fecam.py] => Task 0, Epoch 97/200 => Loss 0.771, Train_accy 77.71
2024-06-18 20:18:37,053 [fecam.py] => Task 0, Epoch 98/200 => Loss 0.768, Train_accy 77.56
2024-06-18 20:18:40,642 [fecam.py] => Task 0, Epoch 99/200 => Loss 0.754, Train_accy 78.00
2024-06-18 20:18:44,237 [fecam.py] => Task 0, Epoch 100/200 => Loss 0.737, Train_accy 78.84
2024-06-18 20:18:48,763 [fecam.py] => Task 0, Epoch 101/200 => Loss 0.745, Train_accy 78.40, Test_accy 72.88
2024-06-18 20:18:52,315 [fecam.py] => Task 0, Epoch 102/200 => Loss 0.733, Train_accy 78.73
2024-06-18 20:18:55,908 [fecam.py] => Task 0, Epoch 103/200 => Loss 0.725, Train_accy 78.84
2024-06-18 20:18:59,480 [fecam.py] => Task 0, Epoch 104/200 => Loss 0.713, Train_accy 79.43
2024-06-18 20:19:03,041 [fecam.py] => Task 0, Epoch 105/200 => Loss 0.712, Train_accy 79.22
2024-06-18 20:19:07,588 [fecam.py] => Task 0, Epoch 106/200 => Loss 0.705, Train_accy 79.76, Test_accy 74.08
2024-06-18 20:19:11,138 [fecam.py] => Task 0, Epoch 107/200 => Loss 0.696, Train_accy 79.65
2024-06-18 20:19:14,720 [fecam.py] => Task 0, Epoch 108/200 => Loss 0.676, Train_accy 80.48
2024-06-18 20:19:18,317 [fecam.py] => Task 0, Epoch 109/200 => Loss 0.681, Train_accy 80.24
2024-06-18 20:19:21,871 [fecam.py] => Task 0, Epoch 110/200 => Loss 0.656, Train_accy 80.95
2024-06-18 20:19:26,411 [fecam.py] => Task 0, Epoch 111/200 => Loss 0.678, Train_accy 79.99, Test_accy 72.50
2024-06-18 20:19:29,978 [fecam.py] => Task 0, Epoch 112/200 => Loss 0.650, Train_accy 81.39
2024-06-18 20:19:33,552 [fecam.py] => Task 0, Epoch 113/200 => Loss 0.648, Train_accy 81.31
2024-06-18 20:19:37,122 [fecam.py] => Task 0, Epoch 114/200 => Loss 0.629, Train_accy 81.79
2024-06-18 20:19:40,683 [fecam.py] => Task 0, Epoch 115/200 => Loss 0.635, Train_accy 81.70
2024-06-18 20:19:45,227 [fecam.py] => Task 0, Epoch 116/200 => Loss 0.628, Train_accy 81.69, Test_accy 75.90
2024-06-18 20:19:48,671 [fecam.py] => Task 0, Epoch 117/200 => Loss 0.604, Train_accy 82.40
2024-06-18 20:19:52,230 [fecam.py] => Task 0, Epoch 118/200 => Loss 0.598, Train_accy 82.93
2024-06-18 20:19:55,789 [fecam.py] => Task 0, Epoch 119/200 => Loss 0.590, Train_accy 82.90
2024-06-18 20:19:59,334 [fecam.py] => Task 0, Epoch 120/200 => Loss 0.602, Train_accy 82.42
2024-06-18 20:20:03,879 [fecam.py] => Task 0, Epoch 121/200 => Loss 0.580, Train_accy 83.33, Test_accy 75.88
2024-06-18 20:20:07,453 [fecam.py] => Task 0, Epoch 122/200 => Loss 0.572, Train_accy 83.64
2024-06-18 20:20:11,005 [fecam.py] => Task 0, Epoch 123/200 => Loss 0.574, Train_accy 83.64
2024-06-18 20:20:14,550 [fecam.py] => Task 0, Epoch 124/200 => Loss 0.548, Train_accy 84.28
2024-06-18 20:20:18,129 [fecam.py] => Task 0, Epoch 125/200 => Loss 0.547, Train_accy 83.98
2024-06-18 20:20:22,660 [fecam.py] => Task 0, Epoch 126/200 => Loss 0.545, Train_accy 84.14, Test_accy 76.00
2024-06-18 20:20:26,239 [fecam.py] => Task 0, Epoch 127/200 => Loss 0.529, Train_accy 84.76
2024-06-18 20:20:29,797 [fecam.py] => Task 0, Epoch 128/200 => Loss 0.532, Train_accy 84.94
2024-06-18 20:20:33,364 [fecam.py] => Task 0, Epoch 129/200 => Loss 0.511, Train_accy 85.01
2024-06-18 20:20:36,944 [fecam.py] => Task 0, Epoch 130/200 => Loss 0.536, Train_accy 84.50
2024-06-18 20:20:41,464 [fecam.py] => Task 0, Epoch 131/200 => Loss 0.496, Train_accy 85.91, Test_accy 78.14
2024-06-18 20:20:45,042 [fecam.py] => Task 0, Epoch 132/200 => Loss 0.481, Train_accy 86.25
2024-06-18 20:20:48,621 [fecam.py] => Task 0, Epoch 133/200 => Loss 0.485, Train_accy 85.84
2024-06-18 20:20:52,180 [fecam.py] => Task 0, Epoch 134/200 => Loss 0.487, Train_accy 86.10
2024-06-18 20:20:55,768 [fecam.py] => Task 0, Epoch 135/200 => Loss 0.459, Train_accy 86.91
2024-06-18 20:21:00,356 [fecam.py] => Task 0, Epoch 136/200 => Loss 0.461, Train_accy 86.95, Test_accy 77.06
2024-06-18 20:21:03,916 [fecam.py] => Task 0, Epoch 137/200 => Loss 0.458, Train_accy 86.92
2024-06-18 20:21:07,488 [fecam.py] => Task 0, Epoch 138/200 => Loss 0.430, Train_accy 87.88
2024-06-18 20:21:11,068 [fecam.py] => Task 0, Epoch 139/200 => Loss 0.431, Train_accy 87.72
2024-06-18 20:21:14,613 [fecam.py] => Task 0, Epoch 140/200 => Loss 0.426, Train_accy 87.88
2024-06-18 20:21:19,170 [fecam.py] => Task 0, Epoch 141/200 => Loss 0.415, Train_accy 88.30, Test_accy 78.34
2024-06-18 20:21:22,712 [fecam.py] => Task 0, Epoch 142/200 => Loss 0.411, Train_accy 88.20
2024-06-18 20:21:26,291 [fecam.py] => Task 0, Epoch 143/200 => Loss 0.398, Train_accy 88.75
2024-06-18 20:21:29,845 [fecam.py] => Task 0, Epoch 144/200 => Loss 0.394, Train_accy 88.81
2024-06-18 20:21:33,401 [fecam.py] => Task 0, Epoch 145/200 => Loss 0.381, Train_accy 89.41
2024-06-18 20:21:37,971 [fecam.py] => Task 0, Epoch 146/200 => Loss 0.370, Train_accy 89.62, Test_accy 78.18
2024-06-18 20:21:41,545 [fecam.py] => Task 0, Epoch 147/200 => Loss 0.369, Train_accy 89.55
2024-06-18 20:21:45,132 [fecam.py] => Task 0, Epoch 148/200 => Loss 0.363, Train_accy 89.86
2024-06-18 20:21:48,692 [fecam.py] => Task 0, Epoch 149/200 => Loss 0.357, Train_accy 89.81
2024-06-18 20:21:52,252 [fecam.py] => Task 0, Epoch 150/200 => Loss 0.334, Train_accy 90.49
2024-06-18 20:21:56,820 [fecam.py] => Task 0, Epoch 151/200 => Loss 0.333, Train_accy 90.66, Test_accy 78.64
2024-06-18 20:22:00,379 [fecam.py] => Task 0, Epoch 152/200 => Loss 0.340, Train_accy 90.51
2024-06-18 20:22:03,944 [fecam.py] => Task 0, Epoch 153/200 => Loss 0.324, Train_accy 90.90
2024-06-18 20:22:07,491 [fecam.py] => Task 0, Epoch 154/200 => Loss 0.311, Train_accy 91.32
2024-06-18 20:22:11,039 [fecam.py] => Task 0, Epoch 155/200 => Loss 0.310, Train_accy 91.45
2024-06-18 20:22:15,579 [fecam.py] => Task 0, Epoch 156/200 => Loss 0.312, Train_accy 91.40, Test_accy 80.38
2024-06-18 20:22:19,141 [fecam.py] => Task 0, Epoch 157/200 => Loss 0.291, Train_accy 91.82
2024-06-18 20:22:22,685 [fecam.py] => Task 0, Epoch 158/200 => Loss 0.294, Train_accy 91.65
2024-06-18 20:22:26,257 [fecam.py] => Task 0, Epoch 159/200 => Loss 0.287, Train_accy 92.13
2024-06-18 20:22:29,804 [fecam.py] => Task 0, Epoch 160/200 => Loss 0.259, Train_accy 92.94
2024-06-18 20:22:34,319 [fecam.py] => Task 0, Epoch 161/200 => Loss 0.263, Train_accy 92.70, Test_accy 80.84
2024-06-18 20:22:37,848 [fecam.py] => Task 0, Epoch 162/200 => Loss 0.258, Train_accy 92.80
2024-06-18 20:22:41,392 [fecam.py] => Task 0, Epoch 163/200 => Loss 0.251, Train_accy 93.10
2024-06-18 20:22:44,943 [fecam.py] => Task 0, Epoch 164/200 => Loss 0.248, Train_accy 93.07
2024-06-18 20:22:48,481 [fecam.py] => Task 0, Epoch 165/200 => Loss 0.240, Train_accy 93.31
2024-06-18 20:22:52,988 [fecam.py] => Task 0, Epoch 166/200 => Loss 0.232, Train_accy 93.68, Test_accy 82.14
2024-06-18 20:22:56,542 [fecam.py] => Task 0, Epoch 167/200 => Loss 0.237, Train_accy 93.50
2024-06-18 20:23:00,085 [fecam.py] => Task 0, Epoch 168/200 => Loss 0.223, Train_accy 94.02
2024-06-18 20:23:03,625 [fecam.py] => Task 0, Epoch 169/200 => Loss 0.208, Train_accy 94.37
2024-06-18 20:23:07,179 [fecam.py] => Task 0, Epoch 170/200 => Loss 0.213, Train_accy 94.16
2024-06-18 20:23:11,720 [fecam.py] => Task 0, Epoch 171/200 => Loss 0.214, Train_accy 94.14, Test_accy 82.18
2024-06-18 20:23:15,288 [fecam.py] => Task 0, Epoch 172/200 => Loss 0.205, Train_accy 94.38
2024-06-18 20:23:18,847 [fecam.py] => Task 0, Epoch 173/200 => Loss 0.207, Train_accy 94.33
2024-06-18 20:23:22,394 [fecam.py] => Task 0, Epoch 174/200 => Loss 0.200, Train_accy 94.49
2024-06-18 20:23:25,940 [fecam.py] => Task 0, Epoch 175/200 => Loss 0.194, Train_accy 94.74
2024-06-18 20:23:30,424 [fecam.py] => Task 0, Epoch 176/200 => Loss 0.194, Train_accy 94.70, Test_accy 83.02
2024-06-18 20:23:33,951 [fecam.py] => Task 0, Epoch 177/200 => Loss 0.175, Train_accy 95.32
2024-06-18 20:23:37,513 [fecam.py] => Task 0, Epoch 178/200 => Loss 0.180, Train_accy 95.09
2024-06-18 20:23:41,072 [fecam.py] => Task 0, Epoch 179/200 => Loss 0.183, Train_accy 95.00
2024-06-18 20:23:44,653 [fecam.py] => Task 0, Epoch 180/200 => Loss 0.179, Train_accy 95.12
2024-06-18 20:23:49,199 [fecam.py] => Task 0, Epoch 181/200 => Loss 0.175, Train_accy 95.18, Test_accy 83.50
2024-06-18 20:23:52,758 [fecam.py] => Task 0, Epoch 182/200 => Loss 0.183, Train_accy 94.95
2024-06-18 20:23:56,317 [fecam.py] => Task 0, Epoch 183/200 => Loss 0.165, Train_accy 95.47
2024-06-18 20:23:59,899 [fecam.py] => Task 0, Epoch 184/200 => Loss 0.171, Train_accy 95.46
2024-06-18 20:24:03,440 [fecam.py] => Task 0, Epoch 185/200 => Loss 0.174, Train_accy 95.23
2024-06-18 20:24:07,961 [fecam.py] => Task 0, Epoch 186/200 => Loss 0.170, Train_accy 95.46, Test_accy 83.42
2024-06-18 20:24:11,520 [fecam.py] => Task 0, Epoch 187/200 => Loss 0.159, Train_accy 95.54
2024-06-18 20:24:15,059 [fecam.py] => Task 0, Epoch 188/200 => Loss 0.157, Train_accy 95.81
2024-06-18 20:24:18,595 [fecam.py] => Task 0, Epoch 189/200 => Loss 0.152, Train_accy 96.04
2024-06-18 20:24:22,173 [fecam.py] => Task 0, Epoch 190/200 => Loss 0.153, Train_accy 95.85
2024-06-18 20:24:26,681 [fecam.py] => Task 0, Epoch 191/200 => Loss 0.154, Train_accy 95.90, Test_accy 83.64
2024-06-18 20:24:30,217 [fecam.py] => Task 0, Epoch 192/200 => Loss 0.149, Train_accy 96.04
2024-06-18 20:24:33,764 [fecam.py] => Task 0, Epoch 193/200 => Loss 0.161, Train_accy 95.58
2024-06-18 20:24:37,341 [fecam.py] => Task 0, Epoch 194/200 => Loss 0.155, Train_accy 95.83
2024-06-18 20:24:40,905 [fecam.py] => Task 0, Epoch 195/200 => Loss 0.151, Train_accy 95.94
2024-06-18 20:24:45,471 [fecam.py] => Task 0, Epoch 196/200 => Loss 0.148, Train_accy 96.09, Test_accy 83.94
2024-06-18 20:24:49,055 [fecam.py] => Task 0, Epoch 197/200 => Loss 0.142, Train_accy 96.12
2024-06-18 20:24:52,596 [fecam.py] => Task 0, Epoch 198/200 => Loss 0.148, Train_accy 95.99
2024-06-18 20:24:56,165 [fecam.py] => Task 0, Epoch 199/200 => Loss 0.151, Train_accy 95.90
2024-06-18 20:24:59,739 [fecam.py] => Task 0, Epoch 200/200 => Loss 0.158, Train_accy 95.82
2024-06-18 20:25:53,641 [trainer.py] => CNN: {'total': 83.94, '00-09': 86.8, '10-19': 80.7, '20-29': 86.7, '30-39': 80.2, '40-49': 85.3, 'old': 0, 'new': 83.94}
2024-06-18 20:25:53,642 [trainer.py] => No NME accuracy
2024-06-18 20:25:53,642 [trainer.py] => FeCAM: {'total': 83.94, '00-09': 86.8, '10-19': 80.7, '20-29': 86.7, '30-39': 80.2, '40-49': 85.3, 'old': 0, 'new': 83.94}
2024-06-18 20:25:53,642 [trainer.py] => CNN top1 curve: [83.94]
2024-06-18 20:25:53,642 [trainer.py] => CNN top5 curve: [96.42]
2024-06-18 20:25:53,642 [trainer.py] => FeCAM top1 curve: [83.94]
2024-06-18 20:25:53,642 [trainer.py] => FeCAM top5 curve: [96.42]

2024-06-18 20:25:53,645 [fecam.py] => Learning on 50-55
2024-06-18 20:26:05,293 [trainer.py] => CNN: {'total': 77.16, '00-09': 82.6, '10-19': 78.3, '20-29': 83.3, '30-39': 76.0, '40-49': 68.9, '50-59': 70.6, 'old': 77.82, 'new': 70.6}
2024-06-18 20:26:05,293 [trainer.py] => No NME accuracy
2024-06-18 20:26:05,293 [trainer.py] => FeCAM: {'total': 80.6, '00-09': 85.6, '10-19': 79.5, '20-29': 85.8, '30-39': 80.5, '40-49': 82.5, '50-59': 58.8, 'old': 82.78, 'new': 58.8}
2024-06-18 20:26:05,293 [trainer.py] => CNN top1 curve: [83.94, 77.16]
2024-06-18 20:26:05,293 [trainer.py] => CNN top5 curve: [96.42, 94.4]
2024-06-18 20:26:05,293 [trainer.py] => FeCAM top1 curve: [83.94, 80.6]
2024-06-18 20:26:05,293 [trainer.py] => FeCAM top5 curve: [96.42, 95.62]

2024-06-18 20:26:05,296 [fecam.py] => Learning on 55-60
2024-06-18 20:26:17,317 [trainer.py] => CNN: {'total': 71.93, '00-09': 80.7, '10-19': 73.8, '20-29': 80.5, '30-39': 75.3, '40-49': 67.4, '50-59': 53.9, 'old': 74.73, 'new': 41.2}
2024-06-18 20:26:17,317 [trainer.py] => No NME accuracy
2024-06-18 20:26:17,317 [trainer.py] => FeCAM: {'total': 76.53, '00-09': 84.7, '10-19': 77.3, '20-29': 84.1, '30-39': 79.7, '40-49': 81.9, '50-59': 51.5, 'old': 79.4, 'new': 45.0}
2024-06-18 20:26:17,317 [trainer.py] => CNN top1 curve: [83.94, 77.16, 71.93]
2024-06-18 20:26:17,317 [trainer.py] => CNN top5 curve: [96.42, 94.4, 89.77]
2024-06-18 20:26:17,317 [trainer.py] => FeCAM top1 curve: [83.94, 80.6, 76.53]
2024-06-18 20:26:17,317 [trainer.py] => FeCAM top5 curve: [96.42, 95.62, 93.2]

2024-06-18 20:26:17,321 [fecam.py] => Learning on 60-65
2024-06-18 20:26:30,518 [trainer.py] => CNN: {'total': 68.32, '00-09': 80.3, '10-19': 73.4, '20-29': 80.3, '30-39': 73.8, '40-49': 63.2, '50-59': 49.9, '60-69': 46.4, 'old': 70.15, 'new': 46.4}
2024-06-18 20:26:30,518 [trainer.py] => No NME accuracy
2024-06-18 20:26:30,518 [trainer.py] => FeCAM: {'total': 74.06, '00-09': 84.5, '10-19': 76.8, '20-29': 84.1, '30-39': 78.7, '40-49': 81.2, '50-59': 49.1, '60-69': 54.0, 'old': 75.73, 'new': 54.0}
2024-06-18 20:26:30,518 [trainer.py] => CNN top1 curve: [83.94, 77.16, 71.93, 68.32]
2024-06-18 20:26:30,518 [trainer.py] => CNN top5 curve: [96.42, 94.4, 89.77, 87.52]
2024-06-18 20:26:30,518 [trainer.py] => FeCAM top1 curve: [83.94, 80.6, 76.53, 74.06]
2024-06-18 20:26:30,518 [trainer.py] => FeCAM top5 curve: [96.42, 95.62, 93.2, 91.91]

2024-06-18 20:26:30,522 [fecam.py] => Learning on 65-70
2024-06-18 20:26:43,741 [trainer.py] => CNN: {'total': 64.56, '00-09': 73.0, '10-19': 71.2, '20-29': 78.1, '30-39': 72.0, '40-49': 62.9, '50-59': 46.3, '60-69': 48.4, 'old': 65.29, 'new': 55.0}
2024-06-18 20:26:43,741 [trainer.py] => No NME accuracy
2024-06-18 20:26:43,741 [trainer.py] => FeCAM: {'total': 72.43, '00-09': 83.9, '10-19': 75.9, '20-29': 83.9, '30-39': 78.7, '40-49': 80.8, '50-59': 48.3, '60-69': 55.5, 'old': 73.45, 'new': 59.2}
2024-06-18 20:26:43,741 [trainer.py] => CNN top1 curve: [83.94, 77.16, 71.93, 68.32, 64.56]
2024-06-18 20:26:43,741 [trainer.py] => CNN top5 curve: [96.42, 94.4, 89.77, 87.52, 86.67]
2024-06-18 20:26:43,741 [trainer.py] => FeCAM top1 curve: [83.94, 80.6, 76.53, 74.06, 72.43]
2024-06-18 20:26:43,741 [trainer.py] => FeCAM top5 curve: [96.42, 95.62, 93.2, 91.91, 91.24]

2024-06-18 20:26:43,745 [fecam.py] => Learning on 70-75
2024-06-18 20:26:57,540 [trainer.py] => CNN: {'total': 62.04, '00-09': 72.6, '10-19': 70.4, '20-29': 77.9, '30-39': 70.7, '40-49': 62.9, '50-59': 43.3, '60-69': 45.9, '70-79': 43.2, 'old': 63.39, 'new': 43.2}
2024-06-18 20:26:57,541 [trainer.py] => No NME accuracy
2024-06-18 20:26:57,541 [trainer.py] => FeCAM: {'total': 70.2, '00-09': 83.8, '10-19': 75.6, '20-29': 83.6, '30-39': 77.6, '40-49': 80.3, '50-59': 46.5, '60-69': 53.6, '70-79': 51.0, 'old': 71.57, 'new': 51.0}
2024-06-18 20:26:57,541 [trainer.py] => CNN top1 curve: [83.94, 77.16, 71.93, 68.32, 64.56, 62.04]
2024-06-18 20:26:57,541 [trainer.py] => CNN top5 curve: [96.42, 94.4, 89.77, 87.52, 86.67, 85.16]
2024-06-18 20:26:57,541 [trainer.py] => FeCAM top1 curve: [83.94, 80.6, 76.53, 74.06, 72.43, 70.2]
2024-06-18 20:26:57,541 [trainer.py] => FeCAM top5 curve: [96.42, 95.62, 93.2, 91.91, 91.24, 90.0]

2024-06-18 20:26:57,545 [fecam.py] => Learning on 75-80
2024-06-18 20:27:12,264 [trainer.py] => CNN: {'total': 59.34, '00-09': 71.7, '10-19': 70.4, '20-29': 77.9, '30-39': 70.6, '40-49': 60.6, '50-59': 36.2, '60-69': 44.6, '70-79': 42.7, 'old': 60.31, 'new': 44.8}
2024-06-18 20:27:12,264 [trainer.py] => No NME accuracy
2024-06-18 20:27:12,264 [trainer.py] => FeCAM: {'total': 68.34, '00-09': 83.6, '10-19': 75.6, '20-29': 83.3, '30-39': 77.3, '40-49': 79.4, '50-59': 44.2, '60-69': 53.2, '70-79': 50.1, 'old': 69.57, 'new': 49.8}
2024-06-18 20:27:12,264 [trainer.py] => CNN top1 curve: [83.94, 77.16, 71.93, 68.32, 64.56, 62.04, 59.34]
2024-06-18 20:27:12,264 [trainer.py] => CNN top5 curve: [96.42, 94.4, 89.77, 87.52, 86.67, 85.16, 84.25]
2024-06-18 20:27:12,264 [trainer.py] => FeCAM top1 curve: [83.94, 80.6, 76.53, 74.06, 72.43, 70.2, 68.34]
2024-06-18 20:27:12,264 [trainer.py] => FeCAM top5 curve: [96.42, 95.62, 93.2, 91.91, 91.24, 90.0, 89.4]

2024-06-18 20:27:12,268 [fecam.py] => Learning on 80-85
2024-06-18 20:27:27,267 [trainer.py] => CNN: {'total': 56.78, '00-09': 70.0, '10-19': 64.8, '20-29': 74.0, '30-39': 70.5, '40-49': 57.0, '50-59': 34.2, '60-69': 41.8, '70-79': 41.6, '80-89': 57.4, 'old': 56.74, 'new': 57.4}
2024-06-18 20:27:27,268 [trainer.py] => No NME accuracy
2024-06-18 20:27:27,268 [trainer.py] => FeCAM: {'total': 66.87, '00-09': 82.9, '10-19': 74.6, '20-29': 82.5, '30-39': 76.5, '40-49': 78.0, '50-59': 43.6, '60-69': 52.2, '70-79': 49.8, '80-89': 56.6, 'old': 67.51, 'new': 56.6}
2024-06-18 20:27:27,268 [trainer.py] => CNN top1 curve: [83.94, 77.16, 71.93, 68.32, 64.56, 62.04, 59.34, 56.78]
2024-06-18 20:27:27,268 [trainer.py] => CNN top5 curve: [96.42, 94.4, 89.77, 87.52, 86.67, 85.16, 84.25, 83.74]
2024-06-18 20:27:27,268 [trainer.py] => FeCAM top1 curve: [83.94, 80.6, 76.53, 74.06, 72.43, 70.2, 68.34, 66.87]
2024-06-18 20:27:27,268 [trainer.py] => FeCAM top5 curve: [96.42, 95.62, 93.2, 91.91, 91.24, 90.0, 89.4, 89.11]

2024-06-18 20:27:27,271 [fecam.py] => Learning on 85-90
2024-06-18 20:27:43,176 [trainer.py] => CNN: {'total': 54.06, '00-09': 66.7, '10-19': 63.9, '20-29': 73.7, '30-39': 70.5, '40-49': 56.9, '50-59': 31.7, '60-69': 40.6, '70-79': 39.2, '80-89': 43.3, 'old': 55.49, 'new': 29.6}
2024-06-18 20:27:43,177 [trainer.py] => No NME accuracy
2024-06-18 20:27:43,177 [trainer.py] => FeCAM: {'total': 64.7, '00-09': 81.8, '10-19': 74.2, '20-29': 82.2, '30-39': 76.5, '40-49': 77.7, '50-59': 42.8, '60-69': 51.7, '70-79': 48.1, '80-89': 47.3, 'old': 66.27, 'new': 38.0}
2024-06-18 20:27:43,177 [trainer.py] => CNN top1 curve: [83.94, 77.16, 71.93, 68.32, 64.56, 62.04, 59.34, 56.78, 54.06]
2024-06-18 20:27:43,177 [trainer.py] => CNN top5 curve: [96.42, 94.4, 89.77, 87.52, 86.67, 85.16, 84.25, 83.74, 82.02]
2024-06-18 20:27:43,177 [trainer.py] => FeCAM top1 curve: [83.94, 80.6, 76.53, 74.06, 72.43, 70.2, 68.34, 66.87, 64.7]
2024-06-18 20:27:43,177 [trainer.py] => FeCAM top5 curve: [96.42, 95.62, 93.2, 91.91, 91.24, 90.0, 89.4, 89.11, 88.01]

2024-06-18 20:27:43,180 [fecam.py] => Learning on 90-95
2024-06-18 20:27:59,665 [trainer.py] => CNN: {'total': 51.79, '00-09': 58.7, '10-19': 63.6, '20-29': 73.6, '30-39': 70.4, '40-49': 56.6, '50-59': 31.0, '60-69': 39.7, '70-79': 37.0, '80-89': 42.0, '90-99': 38.8, 'old': 52.51, 'new': 38.8}
2024-06-18 20:27:59,666 [trainer.py] => No NME accuracy
2024-06-18 20:27:59,666 [trainer.py] => FeCAM: {'total': 63.52, '00-09': 81.3, '10-19': 73.9, '20-29': 82.2, '30-39': 76.4, '40-49': 77.5, '50-59': 42.1, '60-69': 51.1, '70-79': 46.4, '80-89': 46.8, '90-99': 51.4, 'old': 64.19, 'new': 51.4}
2024-06-18 20:27:59,666 [trainer.py] => CNN top1 curve: [83.94, 77.16, 71.93, 68.32, 64.56, 62.04, 59.34, 56.78, 54.06, 51.79]
2024-06-18 20:27:59,666 [trainer.py] => CNN top5 curve: [96.42, 94.4, 89.77, 87.52, 86.67, 85.16, 84.25, 83.74, 82.02, 80.67]
2024-06-18 20:27:59,666 [trainer.py] => FeCAM top1 curve: [83.94, 80.6, 76.53, 74.06, 72.43, 70.2, 68.34, 66.87, 64.7, 63.52]
2024-06-18 20:27:59,666 [trainer.py] => FeCAM top5 curve: [96.42, 95.62, 93.2, 91.91, 91.24, 90.0, 89.4, 89.11, 88.01, 87.2]

2024-06-18 20:27:59,669 [fecam.py] => Learning on 95-100
2024-06-18 20:28:16,390 [trainer.py] => CNN: {'total': 50.27, '00-09': 57.9, '10-19': 63.6, '20-29': 72.7, '30-39': 69.8, '40-49': 56.6, '50-59': 29.2, '60-69': 38.2, '70-79': 36.5, '80-89': 41.3, '90-99': 36.9, 'old': 51.0, 'new': 36.4}
2024-06-18 20:28:16,390 [trainer.py] => No NME accuracy
2024-06-18 20:28:16,390 [trainer.py] => FeCAM: {'total': 62.36, '00-09': 81.2, '10-19': 73.8, '20-29': 81.4, '30-39': 76.0, '40-49': 77.3, '50-59': 40.9, '60-69': 50.9, '70-79': 46.2, '80-89': 46.2, '90-99': 49.7, 'old': 63.04, 'new': 49.4}
2024-06-18 20:28:16,390 [trainer.py] => CNN top1 curve: [83.94, 77.16, 71.93, 68.32, 64.56, 62.04, 59.34, 56.78, 54.06, 51.79, 50.27]
2024-06-18 20:28:16,390 [trainer.py] => CNN top5 curve: [96.42, 94.4, 89.77, 87.52, 86.67, 85.16, 84.25, 83.74, 82.02, 80.67, 79.92]
2024-06-18 20:28:16,390 [trainer.py] => FeCAM top1 curve: [83.94, 80.6, 76.53, 74.06, 72.43, 70.2, 68.34, 66.87, 64.7, 63.52, 62.36]
2024-06-18 20:28:16,390 [trainer.py] => FeCAM top5 curve: [96.42, 95.62, 93.2, 91.91, 91.24, 90.0, 89.4, 89.11, 88.01, 87.2, 86.68]

